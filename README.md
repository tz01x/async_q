# AsyncQ
A simple worker task queue with async support

## Features
1. Submit I/O bound task to run in asynchronously in the worker process 
2. Worker process can be run on different machine

## Use Case: Asynchronous Task Queue for I/O-Bound Task Processing

### Overview
In scenarios where you need to execute I/O-bound tasks asynchronously within a single application, the "AsyncQ" library provides a straightforward solution. This use case illustrates how to create and utilize the library for such purposes.

### Prerequisites
Before using the "AsyncQ" library, ensure you have Python 3.10 and Redis (Version 5.0 to current) installed, along with the required dependencies.

### Setting Up the Application

#### 1. Creating the Async Task Queue App
Begin by creating an instance of the `AsyncTaskQueue` to set up your application. In this example, we will name our app "async_q_app" and configure it to use Redis as the message broker.

```python
# main_app.py

from async_q import AsyncTaskQueue, RedisBuilder

# Define Async Task Queue App
async_q_app = AsyncTaskQueue(
    redis_builder=RedisBuilder(
        port='6379',
    )
)
```

#### 2. Defining the Task Function
Next, define a task function that will be submitted to the queue for processing. In this example, we have a task function named `my_task`. This function simulates I/O waiting with a specified delay.

```python
# my_task.py

import logging
import asyncio
from async_q import submit_task

# For initializing the app
from main_app import async_q_app

async def my_task(idx, delay=2, *args, **kwargs):
    # Simulate I/O waiting
    await asyncio.sleep(delay)

    logging.info(f'{idx} has finished the task. Task ID: {kwargs.get("task_id")}')
```

#### 3. Submitting Tasks
To submit tasks for processing, you can use the `submit_task` function. In this example, we submit 20 tasks to be processed by the queue.

```python
if __name__ == '__main__':
    for i in range(20):
        submit_task(my_task, kwargs={'idx': i, 'delay': 10})
```

### Running Worker Processes

#### 4. Starting Worker Processes
To process the submitted tasks, you need to start one or more worker processes. You can specify the number of concurrent workers using the `-c` flag. In this case, we'll start 5 worker processes by pointing to the `async_q_app` defined in `main_app.py`.

```bash
$ python -m async_q -a main_app.py:async_q_app -c 5
```

#### 5. Submitting Tasks for Processing
With the worker processes running, you can now submit tasks for processing. Use the following command to execute the `my_task.py` script, which submits tasks to the queue.

```bash
$ python my_task.py
```

### Result
The worker processes will asynchronously process the submitted tasks with the specified delays. You can monitor the progress and completion of tasks through log messages generated by the `my_task` function. The "Async Queue" library is suitable for I/O-bound workloads that benefit from asynchronous processing within a single application.

## Todo
1. Add route to submit task in different distributed worker process

